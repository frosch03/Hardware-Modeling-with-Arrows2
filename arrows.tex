%\documentclass[11pt,final,a4paper,leqno]{article}
\documentclass[11pt,final,a4paper]{article}
\usepackage[ngerman,english]{babel}
%\usepackage{ucs}
\usepackage[T1]{fontenc}
\usepackage{color}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{listings}
\usepackage{fancyvrb}
\usepackage{textcomp}
\usepackage{setspace}
%\usepackage{MnSymbol}
\usepackage{amsmath} % flush eqations to the left

\lstnewenvironment{haskell}[1][]{
  \lstset{
    fancyvrb=true, columns=flexible, language=haskell,
    captionpos=b,
    basicstyle=\ttfamily\small\setstretch{1},
    commentstyle=\color{ggray}\slshape,
    upquote=true,
    escapechar={@},
    emph={True,False}, emphstyle=\color{green},
    literate=*{...}{{\textcolor{ggray}{...}}}{3}%
             {\{}{{\textcolor{blue}{\{}}}{1}%
             {\}}{{\textcolor{blue}{\}}}}{1}%
             {->}{{$\rightarrow$}}{4},
    stringstyle=\color{red}, showstringspaces=false,
    keywordstyle=\color{blue},#1
}}{}


% Commands
\newcommand{\hs}[1]{%
  \lstinline[
    fancyvrb=true, columns=flexible, language=haskell,
    captionpos=b,
    basicstyle=\ttfamily\setstretch{1},
    commentstyle=\color{ggray}\slshape,
    upquote=true,
    escapechar={@},
    emph={True,False}, emphstyle=\color{green},
    literate=*{...}{{\textcolor{ggray}{...}}}{3}%
             {\{}{{\textcolor{blue}{\{}}}{1}%
             {\}}{{\textcolor{blue}{\}}}}{1}%
             {->}{{$\rightarrow$ }}{2},
    stringstyle=\color{red}, showstringspaces=false,
    keywordstyle=\color{blue}]!#1!%
}
\newcommand{\grafik}[4][0.9]{%        % Bild einfügen, [Skalierung], {Dateiname ohne Endung}, {Beschriftung}, {label zum Referenzieren}
    \begin{figure}[ht]%               % before: htbp 
        \begin{center}
            \includegraphics[width=#1\columnwidth]{Images/#2}
            \caption{\label{#4} #3}
            
        \end{center}
    \end{figure}
}
\newcommand{\xfig}[4][0.9] {%      %xfig figure einfügen, [Skalierung], {Dateiname ohne Endung}, {Beschriftung}, {label}
    \begin{figure}[ht]
        \begin{center}
%            \graphicspath{{./}{Images/}}
            \scalebox{#1}{%
%                \input{Images/#2}
                \input{#2}
            }
            \caption{\label{#4} #3}
        \end{center}
    \end{figure}
}
\newcommand{\reFLect}{\textit{re\kern-0.07em F\kern-0.07emL\kern-0.29em\raisebox{0.56ex}{ect}}}
\newcommand{\boxit}[1]{\mbox{{\it #1}}}

% Colors
\definecolor{gray}{gray}{0.5}
\definecolor{ggray}{gray}{0.7}
\definecolor{green}{rgb}{0,0.5,0}
\definecolor{textgray}{gray}{0.25}
\definecolor{backgray}{gray}{0.95}


\title{Hardware Design with Functional Datastructures: Functions, Arrows, Tupels, Vectors, and Inspection} 

\begin{document}

\section{Introduction}

\section{Hardware Modeling in the Functional Programming Paradigm: Recent Approaches}
\label{recent_approaches}
% TODO : Is stated in intro? 
As stated in the introduction, modeling hardware in functional languages is old news, there have been various approaches in the
past. The beginning dates back to the early 80s where a group around Mary Sheeran came up with a functional HDL (Hardware
Description Language) muFP\cite{sheeran:muFP}. In the same decade John O'Donnell presented his functional HDL
HDRE\cite{hydra:old,donnell}. These two HDL's gave birth to numerous later approaches that are base more or less on them.

One of Sheeran's students, Coen Claessen, later came up with a monadic solution called Lava\cite{claessen:hardware}. Ingo Sanders
et al introduced an approach, ForSyDe \cite{forsyde:phd,forsyde:ieee} that is based on meta programming techniques. Lava, ForSyDe
and also Hydra %TODO : Hydra reference in literature
represent HDL's embedded around the functional programming language Haskell; MyHDL \cite{myhdl} is embedded in the functional
flavored interpreter language Python. There is HML\cite{hml}, a simple HDL which is embedded inside ML, another functional
programming language.

Than there are functional languages that are exclusively designed to describe hardware, like the language SAFL (=Statically
Allocated Functional Language)\cite{sharp,sharp:flash,sharp:codesign}. This one compiles direct into a netlist; it does not
support dynamic allocated storage like heaps or stacks since these kind of software features do not map well on silicone.

Another candidate for the functional meta programming languages section is the language \reFLect \cite{reflect}. It's one that is
developed at Intel and tailored for hardware design and theorem proving.

There are good reasons why meta programming (also called \emph{reflexivity}) is beneficial for the use as HDLs. Meta programming
allows a program to have a representation of itself, usually by providing data structure of the abstract syntax tree. With this
tool at hand the developer is able to \emph{compute} parts of their program rather than \emph{write}them. This leads to a direct
and natural implementation of program transformations. Haskell also allows to meta programming through a library called ``Template
Haskell''\cite{haskell:template}. 
% TODO : Warum werden Haskells Meta-Programming fähigkeiten stifmütterlich behandelt? 

With cryptol\cite{cryptol:programming} another class of functional HDLs enters the scene. While all the other HDL's are general
purpose, cryptol is designed to model cryptographic hardware. A sub-language of cryptol is designed by Galois, explicit to generate
FPGA implementations \cite{cryptol:fpga}. Cryptol has lately been adopted by an American agency and isn't public developed
anymore.

\section{Arrows for Hardware development}
% TODO : Cite: Generalizing Monads to arrows
Arrows are lately developed concept in functional programming. They are best described in short as generalized Monads. Arrows
enable a data flow view onto problems. This fits the hardware developers view which has always been a data flow view, as in
circuit board layouts or in state flow diagrams. The arrow \emph{proc}-notation also transports the data flow view into the
source. %TODO: cite ross patterson
Its easy to generate netlists out of arrows, which basically boils down to a pretty print function. This also holds for the
generation of typical HDL code like VHDL. They can be used to simulate behavior or proof properties of the circuit. This section
gives a brief overview of the \hs{Grid}-Arrow that can be used to generate VHDL code or to simulate a circuit.

\subsection{Grid-Arrow}
The \hs{Grid}-Arrow is a combination of an executable arrow and a descriptive hardware component part. In a first approach one can
imagine the descriptive part to live inside the arrow. But that does not work out, so they are stored equal to each other inside a
tuple. The arrow resides in the first, the graph occupies the second part of the tuple.
\begin{haskell}
  newtype Grid a b c = GR (a b c, CircuitDescriptor)
\end{haskell} 
Alongside with the arrow execution, the generated Netlist is stored inside the graph like data structure called a
\hs{CircuitDescriptor}.  The name Grid is analog chosen to the snap circuit toys from childhood, where one also could combine
hardware elements arbitrary. The Grid type is a surface where hardware elements can be combined with each other to compose new
structures and analyze them. But it is not only the surface to combine hardware components, it's also a recursive surface. So it
is used as hardware component itself which means a \hs{Grid} is an arrow on its own.


\subsection{Circuit-Descriptor}
The descriptive part of the arrow is called a \hs{CircuitDescriptor}. Something of type \hs{CircuitDescriptor}, like the name
suggests, describes a circuit in detail. The combination sequence of the hardware parts, the pin layout, their cabling structure
and also recursively all subcomponents are represented inside the \hs{CircuitDescriptor}. A circuit with such a descriptor has
enough detail to be expressed as a Netlist.

\par
The actual data type is divided into three\footnote{actually four, because the empty descriptor requires it's own} unique
descriptors:
\begin{itemize}
\item \emph{Combinatorial:} are the parts of a circuit that are describable without a clock or buffered data. For example all
  Boolean logic gates fall into this category.
\item \emph{Register:} A register is used to describe the storage of data on the one hand and is used to clock computations on the
  other hand. The implementation of a register highly depends on the target platform. There is no need to know it's details at
  this point.
\item \emph{Loop:} Those Hardware components that are referring onto them self are handled in the looping section.
\end{itemize}

\begin{haskell}
  data CircuitDescriptor
    = MkCombinatorial
      { nodeDesc :: NodeDescriptor
      , nodes    :: [CircuitDescriptor]
      , edges    :: [Edge]
      , cycles   :: Tick
      , space    :: Area
      }
    | MkRegister
      { nodeDesc :: NodeDescriptor
      , bit      :: Int
      }
    | MkLoop
      { nodeDesc :: NodeDescriptor
      , nodes    :: [CircuitDescriptor]
      , edges    :: [Edge]
      , cycles   :: Tick
      , space    :: Area
      }
    | NoDescriptor
    deriving (Eq)
  type Netlist = CircuitDescriptor
\end{haskell} 

The \hs{MkCombinatorial} and the \hs{MkLoop} parts reveal a classic functional graph structure that is build from two lists. One
containing the edges (\hs{edges :: [Edge]}) and the other containing the nodes (\hs{nodes :: [CircuitDescriptor]}).  Additionally
there are information that are equal for every circuit and are stored inside the (\hs{nodeDesc :: NodeDescriptor}) with the graph. At last, information about the hardware's performance (space and time) is stored alongside with the graph.
\begin{haskell}
  data NodeDescriptor
    = MkNode
      { label   :: String 
      , nodeId  :: ID
      , sinks   :: Pins
      , sources :: Pins
      }
    deriving (Eq)
\end{haskell} 
% Each node itself is a \hs{CircuitDescriptor} and contains a list of \hs{CircuitDescriptor}s, so each node could be described
% recursively, which suits hardware very well.

A general problem with such data structures is, they do describe a graph but they don't enforce to build a correct one. In such
cases it's common to supply \hs{smart constructor}s along with the data type. These constructors are functions that take all the
elements the actual \hs{CircuitDescriptor} exists of. Than they check the inputs against given constraints and only generate the
output if the input fulfills them. In that way it's assured that only valid hardware components are constructed.

\par
For example the combinatorial section only accepts non looping connections. A wire is a connection between two \hs{Pins} of one or
two hardware components. The output pin is called the source and the input pin is called the sink of a component. Our approach enforces that every component on a Grid is wired up. 
\begin{haskell}
  type Anchor       = (Maybe CompID, PinID)
\end{haskell}
The outer most grid can't be wired up as it represents a not yet placed piece of hardware. This is mirrored by the \hs{Maybe
  CompID} in the type of an anchor. \xfig[.9]{ic-pin.pspdftex}{Image of IC {\tiny (by Sergei Frolov)}}{img:ic-with-pin}

\subsection{Lists through Tuples}
The Haskell arrow interface is build upon tuples and therefore prefers them. Circuits come often with a list like interface so we
model them with tuples. There are operators, like binary logic operators, that perfectly match the tuple structure. In example,
component $C_0$ produces the outputs $s_0, s_1, s_2, s_3$. Another component $C_1$ processes $s_0$ and $s_2$; $C_2$ acts on $s_1$
and $s_3$. The process of restructuring the output of one function into an input to another function is called retuple'ing because
it is only possible to change the way data is tupled into each other. As example a function that does such tuple'ing is \hs{mvRight}. This one takes an argument of the structure \((x,(y,z))\) to a different structure \((y,(x,z))\).

\begin{haskell}
mvRight :: (Arrow a) => Grid a (my, (b, rst)) (b, (my, rst))
mvRight           -- aFloatR
  =   aDistr      -- aDistr : is that really aDistr?
  >>> first aSnd
\end{haskell} 

There are two arrows involved here, \hs{aDistr} and \hs{aSnd}. With \hs{aDistr} the first element is distributed over the second
one and with \hs{first aSnd} the first occurrence is dropped. The \hs{mvRight} arrow floats the first element one position to the
right. Of curse this arrow assumes a structure where always the first element of a tuple is a value, the second is another tuple:
\((v_1, (v_2, (v_3, (v_4, v_5, (\dots)))))\)

\par
A common task over the list like tuples is to apply an arrow to the front and than concentrate the remaining calculation on the
remaining inner structure. For this purpose the operator \hs{>:>} helps to clarify the code that describes such computations.
\begin{haskell}
  aA >:> aB = aA >>> (second aB)
\end{haskell} 

The operator \hs{>:>} is based on the \hs{>>>} operator with a difference. The first supplied arrow is executed over the whole
input data tuple, while the second one is applied only to the second part of the tuple. Such an operator comes handy as long list
like tuple structures are used and are processed from the left.

\par
While working with tuple lists, it is often needed to reorder the parenthesis around the data so that selector functions like
\hs{first} process the right data. The two arrows \hs{a\_xXX2XXs} and \hs{a\_XXx2xXX} exploit the associative law of arrows. The
cryptic names mirror the changing structure, upper case letters show the grouped position.
\begin{align*}
  \text{a\_xXX2XXx} &: (a, (b, c)) \rightarrow ((a, b), c) \\
  \text{a\_XXx2xXX} &: ((a, b), c) \rightarrow (a, (b, c))
\end{align*}



\section{First Approach: Classical Arrows}
Within this section we present a cycle redundancy check algorithm, implemented with the design method of arrows. The example shows
a typical way to express hardware functional. Also the flexibility of a functional approach is demonstrated via the implementation
of multiple CRC's.  How to generate netlists out of the functional data structure is shown later on. After that, the problems with
classical arrows are highlighted and solutions are discussed.


\subsection{CRC - Implementation}
A CRC - cycle redundancy check - is a widely used method to calculate checksums of data. The calculation of a CRC is based upon
polynomial division. The reminder of the devision is called the checksum. The input data, added by the checksum, results $0$ if it
is divided again by the polynomial. A method for calculating the CRC checksum is to use a shift register with feedback. In the
following the CRC calculation with a shift register is described.

\par
The shift register in Haskell is modeled with a list and the positions of where the feedback is feed back. If the left most value
of the list is the value that is feed back, a function is needed to move that value through the list. Because the list is
simulated through the use of tuples, moving a value to the right is moving it to the inside.

\par
The \hs{toInner} function makes use of the previously defined operators. There are several \hs{toInner} functions, that only
differ in the amount of steps the value is pushed into the list.
\begin{haskell}
toInner5
  =   mvRight
  >:> mvRight
  >:> mvRight
  >:> mvRight
  >:> aFlip
\end{haskell} 



With \hs{crc\_checksum\_8} a higher order function is defined that abstracts the general principle behind an 8 bit CRC sum
function.
\begin{haskell}
crc_checksum_8 crc_polynom polySkip padding start rest
  =   (padding &&& aId)
  >>> toInner8

  >>> (start &&& rest)
  >>> first (crc_polynom)

  >>> step
  >>> step
  >>> step
  >>> step
  >>> step
  >>> step

  >>> aFlip
  >>> polySkip
  >>> crc_polynom

  where step =   a_xXX2XXx
             >>> first 
                 (   aFlip
                 >>> polySkip
                 >>> crc_polynom
                 )   
\end{haskell} 

Before starting to calculate the CRC, the input data need to be properly aligned. Therefore the padding bits, which are all $0$
for the calculation of the CRC, are ``moved'' to right end of the tuple list which for any 8 bit wide CRC algorithm is done via
the \hs{toInner8}.
\[((p_0, p_1), (b_0, (b_1, (b_2, (b_3, b_4))))) \rightarrow (b_0, (b_1, (b_2, (b_3, (b_4, (p_0, p_1))))))\]

Afterwards the arrow actually abstracts the steps to be done to calculate a 8 bit CRC sum. The combined action \hs{(start &&&
  rest)} splits the input data stream into the just enough bits that fill the Galois type shift register (the \hs{start} part) and
into the remaining bits (the \hs{rest} part). Keep in mind that the \hs{&&&} operator first duplicates its input and passes each
arrow one copy. The starting bits are then fed into the shift register via the \hs{first (crc\_polynom)} expression. Step by step
all the bits are consumed, $1$ bit for every \hs{step}. The last step is executed without the need of the \hs{first} selector,
because there are no reminding bits left and for that reason the arrow ends with the \hs{aFlip >>> polySkip >>> crc\_polynom}
expression.


\subsection{Simple Example}
There are lots of CRC-Codes out there and every one is equipped with a polynomial that especially fits the needs of its domain. In
this examples the simple CRC-Codes for USB and CCIT are shown. Their polynomials are:
\begin{align*}
  \text{USB} &: x^5 + x^2 + 1 \\
  \text{CCIT}&: x^4 + x   + 1 
\end{align*}

These polynomials describe at which positions the input bit is \hs{xor}'ed with that bit that has traveled all the way through the
shift register. For the USB CRC $\text{bit}_0$ and $\text{bit}_2$ are \hs{xor}'ed with $\text{bit}_5$, for the CCIT CRC the
$\text{bit}_0$ and $\text{bit}_1$ are \hs{xor}'ed with $\text{bit}_4$.

\begin{figure}
  \centering
  \graphicspath{{./}{Images/}}
  \mbox{%
    \subfigure[USB CRC]{\scalebox{0.5}{\input{./Images/CRC-USB}}} \quad \quad \quad \quad
    \subfigure[CCIT CRC]{\scalebox{0.5}{\input{./Images/CRC-CCIT}}}
  }
\end{figure}

The question is, what \hs{polySkip}, \hs{crc\_polynom}, \hs{padding}, \hs{start} and \hs{rest} values need to be chosen. To
summarize this for the CCIT CRC, the highest exponent is $4$. This means, that:
\begin{itemize}
  \item the \hs{polySkip} needs to be \hs{toInner4}
  \item there are $4$ \hs{padding} bits \hs{aConst (False, (False, (False, False)))} 
  \item the split between \hs{start} and \hs{rest} is after bit $4$
\end{itemize}

So the resulting definition of the CCIT CRC sum is:
\begin{haskell}
crc_checksum_ccit_8 
  :: Arrow a => Grid a 
    (Bool, (Bool, (Bool, (Bool, (Bool, (Bool, (Bool, Bool))))))) 
    (Bool, (Bool, (Bool, Bool)))
crc_checksum_ccit_8
  = crc_checksum_8   
      crc_polynom_ccit
      toInner4
      (aConst (False, (False, (False, False))))
      (second.second.second.second $ aFst)
      (aSnd >>> aSnd >>> aSnd >>> aSnd >>> aSnd)
\end{haskell} % $ to fix that syntax highlighting problem 


\subsection{Building Netlists}
The data type of the previous CRC function denotes a \hs{Graph} arrow. This is because the arrow generates a graph which in fact
holds all the information that are needed to generate netlists out of it. Basically a graph could be seen as a different form of a
Netlist. In Haskell a graph is modeled by two lists, one for the nodes and one for the edges.


Every hardware component is identified by an ID that is represented by an integer value. This holds also for the in and output
pins of hardware components. The Pins also have IDs that are identified by an integer value.
\begin{haskell}
type CompID = Int
type PinID  = Int
type Pins   = [PinID]
\end{haskell}


An edge represents a wire between two pins on different components and is identified by the tuple of \hs{CompID} and \hs{PinID}
which is called an \hs{AnchorPoint}. There are also two different anchor points, one that goes into a component called
\hs{SinkAnchor} as well as one that comes from a component, the \hs{SourceAnchor}.

\begin{haskell}
type AnchorPoint  = (Maybe CompID, PinID)
type SinkAnchor   = AnchorPoint
type SourceAnchor = AnchorPoint
\end{haskell}

Note that the \hs{Maybe} constructor is used here, because there can be edges / wires from and to nowhere. These represent the
edges of a component which are not yet connected to the outside world. This by the way maps also to the real world, where it is
normal, that components which are not yet placed have pins from and to nowhere.


An edge is a wire, is a connection between two components or to be more precise, it is a connection between two anchor points.
\begin{haskell}
data Edge 
  = MkEdge { sourceInfo :: SourceAnchor
           , sinkInfo   :: SinkAnchor }
\end{haskell}
The record notation is used, to obtain accessor functions (\hs{sourceInfo} and \hs{sinkInfo}) within one step.

 
Last but not least the actual graph is defined. It holds the information about the node which is similar to the component. The
name is later used in the VHDL generation to identify the entities. Every node holds a list of sub nodes that represent from what
this node is build and helps to build up complex structures from basic simple building blocks. It also holds a list of the
connected edges, as well as the list of input- and output pins. Accessor function are also gained through the use of the record
notation.
\begin{haskell}
data StructGraph
  = MkSG { name    :: String
         , compID  :: CompID
         , nodes   :: [StructGraph]
         , edges   :: [Edge]
         , sinks   :: Pins
         , sources :: Pins }   
\end{haskell}


\subsection{Drawbacks}

This approach basically comes with two problems. 

As the CRC example shows up, all the input data to these hardware components must fit into simple tuples. This is easy to handle
if the components only come with one or two pins and certainly which is the case for simple logic gates. But at the latest if the
modeled hardware component uses more than two pins, different data structures are needed. Up to a certain degree one can simulate
a list-like structure with tuples (as it is done in the above CRC examples). But the simulation comes at a cost.  A big part of
the code is needed for restructuring tuples; the CRC example only is an $8$-bit gate and even more restructuring will be necessary
for modeling real world logic gates. This process becomes more tedious, confusing and error prone, if something like 32 bit
hardware components should be modeled.

The tedious tuple code could at least be superficially avoided by the use of Patterson's proc-notation for
arrows\cite{PatersonNewNotation}.  The proc-notation abstracts the tuples code, and the hardware can be described more
``visually'' in the source code. But the proc-notation is just syntactic sugar and underneath there are still tuples in use.  The
following code shows how the CCIT CRC polynomial can be modeled with the proc-notation:
\begin{haskell}
crc_polynom_ccit 
 = proc (b4, (b3, (b2, (b1, b0)))) -> do
     b4' <- aId  -< (b3)
     b3' <- aId  -< (b2)
     b2' <- aXor -< (b4, b1)
     b1' <- aXor -< (b4, b0)
     returnA     -< (b4', (b3', (b2', b1')))
\end{haskell} 

\par
But there is also a problem with the notation that comes from the auto generated arrow code. Patterson's notation makes a lot use
of the \hs{arr} function of an arrow. But because it is possible to ``lift'' any function that is passed to \hs{arr} into an
arrow, it is impossible to keep track of the types of that functions. Nevertheless the type of the passed function is needed to
generate a \hs{Grid} arrow, that can be transformed into Netlists later. That is, because there is a direct correspondence between
the data type of a function and their hardware representation (e.g.\ number of in- output pins).



\section{Coping with the Tupel-Problem - ``Vector-Arrows''}
So classical arrows are an adequate abstract form to describe hardware, they are modular and the come with a enhanced type system
that helps to reduce errors. The part which does not match the hardware perfect is the way the in- and output pins are structured,
the tuples.

\par
As stated earlier, it is somewhat theoretical to work with hardware that come with $\leq2$ in- or output pins. Tuples prefer $2$
in- or output kind of hardware. Also tuples allow anything to be an in- or output. In the digital world, there is only hardware
that transmits boolean values. Integers are transmitted by bundling multiple boolean values. Also the developers of Sensors try to
digitize pretty early in their design process. \cite{MakinwaSmartSensor}

\par
The type \hs{a b c} is too general for a logic gate: the type of the data going into a logic gate should always be the same as the
type of the values coming out of this logic gate. Secondly, a set of wires actually is not a tuple and, for instance, the tuple
\hs{(a,(b,(c,d)))} represents the same set of wires as the tuple \hs{(a,((b,c),d))} and the number of possible (different with
respect to syntax and type) representations of a set of wires exponentially explodes with a growing number wires we are trying to
model.

\par
These properties describe hardware to be static in their type of values and dynamic in their amount of values. Arrows are dynamic
in the type of values but are static in their amount of the values. So arrows are exactly opposing the hardwares nature. The
question is, can arrows be transformed into a different kind of arrows? And is this possible in such a way that they match
hardware more naturally, without loosing the other beneficial properties for hardware design.

\par
It is obvious that a vector fulfills exactly the desired hardware behavior. A vector $Vec_n^b$ is a vector of $n$ values of type
$b$. So vectors are static in their data type ($b$) and are dynamic in their value amount ($n$). In the following we sketch some
ways to express these ``Vector-Arrows'' in Haskell and therefore we present a \emph{Horn-Clauses} like approach, an approach with
\emph{Type-Families} and one with \emph{Dependently Typed Arrows}.

\par
So here is a class definition for a vector arrow. 
\begin{haskell}
class VArrow a where
  arr     :: ((@$Vec_n^{b}$@)-> (@$Vec_m^{b}$@)) -> a (@$Vec_n^{b}$@) (@$Vec_m^{b}$@)
  firsts  :: a (@$Vec_n^{b}$@) (@$Vec_m^{b}$@) -> a (@$Vec_{(n:+k)}^{b}$@) (@$Vec_{(m:+k)}^{b}$@)
  seconds :: a (@$Vec_n^{b}$@) (@$Vec_m^{b}$@) -> a (@$Vec_{(k:+n)}^{b}$@) (@$Vec_{(k:+m)}^{b}$@)
  (>^>)   :: a (@$Vec_n^{b}$@) (@$Vec_m^{b}$@) -> a (@$Vec_m^{b}$@) (@$Vec_k^{b}$@) -> a (@$Vec_n^{b}$@) (@$Vec_k^{b}$@)
  (&^&)   :: a (@$Vec_n^{b}$@) (@$Vec_m^{b}$@) -> a (@$Vec_n^{b}$@) (@$Vec_k^{b}$@) -> a (@$Vec_n^{b}$@) (@$Vec_{(m:+k)}^{b}$@)
  (*^*)   :: a (@$Vec_n^{b}$@) (@$Vec_m^{b}$@) -> a (@$Vec_k^{b}$@) (@$Vec_j^{b}$@) -> a (@$Vec_{(n:+k)}^{b}$@) (@$Vec_{(m:+j)}^{b}$@)
\end{haskell}


\subsection{Horn-like-clause Solution}
A first approach would be to define a list-like data type that is limited in length. Therefore it is necessary to bring a counter,
namely the wire count, into the datatype. Type level natural numbers are the tool to restrict the own list like data type in
length. One ends up with a length limited list, namely a vector.
% TODO, cite richtig platzieren
\cite{kiselyov:strong_collections}
\begin{haskell}
data Vec n a where
  T    :: Vec 'VZero a -- (@$Vec_0^a$@)
  (:.) :: a -> Vec n a -> Vec ('VSucc n) a -- (@$a \rightarrow Vec_n^a \rightarrow Vec_{n+1}^a$@)
\end{haskell} 

\par
The type level natural numbers are introduced as peano numbers. Peano numbers are expressed trough a starting number, that is
usually zero ($VZero$) and a successor function ($VSucc$ $n$) which represents the $n+1$ value. Because Haskell allows the
definition of recursive data types, it is possible to bring natural numbers into a data type. A similar mechanism was showed in
2004 by Kiselyov et al \cite{kiselyov:strong_collections}.

\par
The arrow class defines the functions \hs{arr}, \hs{first}, \hs{second}, \hs{(***)} and \hs{(&&&)}. \hs{arr} takes a Haskell
function into an arrow that expects a vector of $n$ $b$'s ($Vec_n^b$) into a new vector of $b$'s of length $m$ ($Vec_m^b$). The
sequential concatenation of arrows is done by the \hs{(>^>)} operator.\hs{first} translates an arrow into another one, that takes
it's input from the front element of a tuple. \hs{second} does the same thing, but with the second element of that tuple. So these
two functions are uniquely based upon the tuple. With vector arrows there are no tuples, and therefore there is no way to
differentiate a first value from a second one.


\par 
What these two functions do is, they split the input data and only show the firsts or the tail to the submitted arrow. This is
analogue to the projection maps of a cartesian product ($\pi : A \times B \rightarrow A$, $\rho : A \times B \rightarrow B$). So
the \hs{first}-arrow only gets the first piece, the \hs{second}-arrow gets the second one. There aren't such projection maps or
similar functionality for vectors. So at this point it's clear that vector arrows can't be real arrows. This finding and its
aftermath is issued in Section~\ref{notRealArrows} in detail. Nevertheless, it is possible to split a vector into two parts,
namely the first element and the rest of the list. Also this can be done from the back end, so that the list is split into a list
except for the last element and the last element. This leaves us with an \hs{init} and a \hs{last} function. The backwards version
would be a \hs{head} and a \hs{tail} function.

\par
In any way, Haskell is a static typed language which means, everything in the datatype is declared. Therefore all the variables
that hold type level natural numbers are defined in the data type context. Also if the type level integers are added together, the
used type class \hs{VAdd} is listed in the types context. Working with such contexts reminds of the Prolog Horn Clauses and
therefore are responsible for this approach. Combining everything together, an arrow class for vector arrows could look like the
following:

\begin{haskell}
  class (Category a) => VArrow a where
    arr    :: (VNat n)  
           => (Vec n b -> Vec n b) -> a (Vec n b) (Vec n b)


    init   :: ( VNat n, VNat m
              , VAdd n m nm
              , VEq (VSucc n) nm VTrue
              )   
           => a (Vec n b) (Vec m b) -> (Vec nm b) (Vec nm b) -> a (Vec n b) (Vec n b)

    tail   :: ( VNat n, VNat m
              , VAdd n m nm
              , VEq nm (VSucc m) VTrue
              )   
           => a (Vec nm b) (Vec nm b) -> a (Vec m b) (Vec m b)

    tail'  :: ( VNat m ) 
           => a (Vec (VSucc m) b) (Vec (VSucc m) b) -> a (Vec m b) (Vec m b)

    head   :: ( VNat n, VNat m
              , VAdd n m nm
              , VEq nm (VSucc m) VTrue
              )   
           => a (Vec nm b) (Vec nm b) -> a (Vec n b) (Vec n b)

    last   :: ( VNat n, VNat m
              , VAdd n m nm
              , VEq (VSucc n) nm VTrue
              )   
           => a (Vec nm b) (Vec nm b) -> a (Vec m b) (Vec m b)


    (***)  :: (VNat n, VNat m, VAdd n m nm) 
           => a (Vec n b) (Vec n b) -> a (Vec m b) (Vec m b) -> a (Vec nm b) (Vec nm b)

    (&&&)  :: (VNat n, VAdd n n nn) 
           => a (Vec n b) (Vec n b) -> a (Vec n b) (Vec n b) -> a (Vec n b) (Vec nn b)
\end{haskell}

\par
The classical arrow class definition comes with some default definitions. One of them, \hs{a *** b = first a >>> second b},
defines the \hs{(***)}-operator with the help of \hs{first} and \hs{second}. The class definition above doesn't allow such
usage. This is due to the changed nature of \hs{first} and \hs{second} which have become \hs{init}, \hs{tail}, \hs{head} and
\hs{last}. The problem lies within the plurality of possibilities to split a list into halves in contrast to the singular
possibility to divide a tuple.

\par
It is possible to divide the list in just the right spot, once an arrow is known. \hs{first f} needs to split the input vector
into one that has exact the length \hs{f} expects as input, and a rest vector. So with \hs{aXor} being an arrow that takes two
Booleans to one, \hs{first} applied to it is an arrow from at least two Booleans to at least one.
\begin{haskell}
  --      a (Vec 2 Bool) (Vec 1 Bool)
  aXor :: a (Vec (VSucc (VSucc VZero)) Bool) (Vec (VSucc VZero) Bool)

  --              a (Vec 2+k Bool) (Vec 1+k Bool)
  first (aXor) :: (VNat k, VAdd (VSucc (VSucc VZero)) k nk, VAdd (VSucc VZero) k mk)
               => a (Vec ((VSucc (VSucc VZero)) + k) Bool) (Vec ((VSucc VZero) + k) Bool
\end{haskell} 
The $2+k$ is the length of the whole input vector and the output is a vector of length $1+k$. A drawback is, that the actual
syntax isn't sugared. That means it is not possible to write just $2+k$ but instead one has to write \hs{VAdd (VSucc (VSucc
  VZero)) k nk} as a data type context. This might be tedious for easy arrows and becomes an error source for larger arrows.


\subsection{Type-Family Solutions}
Another approach is to replace the Horn like clauses by actual calculations. Haskells type family extension comes in handy for
this task.

\par
A type family is a way to more or less calculate the type constructor of a data type. The horn-clause solution lacks exactly this
feature. The length of the vector is stored in the peano number of that vector. As a peano number is just a bunch of type
constructors, type families could be used to calculate the needed constructor amount. The Haskell-Wiki describes this vividly: A
type family is to a data type, what the method of a type class is to a function.

\par
As the earlier solution showed, the addition is an operator that is needed in the type definition of the arrow methods. So we
illustrate the functionality of a type family by defining an addition operator.
\begin{haskell}
type family (n::VNat)   :+ (m::VNat) :: VNat
type instance VZero     :+ m     = m 
type instance VSucc n   :+ m     = VSucc (n :+ m)
\end{haskell}

% TODO: this section needs to be reformulated
The first thing to do is to define the type family by itself. The type family operator \hs{:+} operates on \hs{VNat}s. Both of the
input values ($n$ and $m$) are added and result in another \hs{VNat} number. The two lines following define the addition function
recursively.  Adding zero to something is just that something; adding one from something to another thing is just the successor of
something added by another thing.

\par
With the addition type family the arrow class could be defined much more similar to the original type class.
\begin{haskell}
class Category a => VArrow a where
  arr     :: (Vec n b -> Vec m b)
          -> a (Vec n b)         (Vec m b)

  firsts  :: a (Vec n b)         (Vec m b)
          -> a (Vec (n :+ k) b)  (Vec (m :+ k) b)

  seconds :: ((m :+ k) ~ (k :+ m))
          => a (Vec n b)         (Vec m b)
          -> a (Vec (k :+ n) b)  (Vec (k :+ m) b)

  (***)   :: a (Vec n  b)        (Vec m  b)
          -> a (Vec n' b)        (Vec m' b)
          -> a (Vec (n :+ n') b) (Vec (m :+ m') b)

  (&&&)   :: a (Vec n b)         (Vec m  b)
          -> a (Vec n b)         (Vec m' b)
          -> a (Vec n b)         (Vec (m :+ m') b)
\end{haskell}

\par 
One problem with this approach is the compiler. It is not possible for GHC to deduce arithmetics in the type context and this is
also valid for simpler calculations. In fact GHC is unable to deduce even the equality of $n+m = m+n$. There are way's to supply the
compiler with that information, so GHC has not to deduce this on its own. But this are only hints into specific directions. Again
this is a point where it is tedious to supply GHC with hints for easy deductions but gets impossible for more complicated
arithmetics.


\subsection{Dependently-Typed Solution}
A dependently typed programming language is a language, that mixes expressions with types. It therefore allows the calculate of
types within that same language. ``Normal'' function definitions come with a well defined type. Polymorphic types are possible and
allow the dfefinition of functions that are more flexible in their type. But polymorphism isn't flexible enough to express data
types like real vectors. In example the addition of two vectors results in a new vector. They type of that new vector then depends
on the type of the input vectors and is the feature that gives such languages their name.

\par
Summarizing the previously expressed solutions they all try to fix a unitary problem. And the problem depends on the fact that
vectors aren't a purely functional data structure in the Haskell sense. For a vector the length of it selfe must show up in it's
data type so that a function can match against it.

\par
The transfer of tuple arrows to vector arrows not only changes the inner data type. Also the projection maps from the inner data
type need to be translated to the vector version. A tuple makes it pretty easy to define projection maps. There are only two
possible solutions, one for the first element \hs{fst} and another one for the last element \hs{snd}. The pendant in the arrow
class are the \hs{first} and \hs{second} functions. These both mirror the typical tuple projection maps in Haskell, namely
\hs{fst} and \hs{snd}. 

\par 
With vectors the \hs{first} statement is straight forward; the \hs{second} expression is more or less the head-scratcher. To
implement the \hs{first} function, the only constraint is, that the input vector is bigger or equal to the one expected by the
function \hs{first} is supplied to. In the \hs{second} case, this constraint also needs to be true, but also the function must be
applied to the sub vector aligned with the end of the input vector. This can either be achieved by calculating the size of the sub
vector that is ignored and than apply the function to the remaining one. It can also be done via reversing the vector multiple
times and than applying the function to the front of the vector. 

\par
In this case it is obvious, that the naming (\hs{first} and \hs{second}) for vectors is at least counter intuitive. For example an
\hs{second aSwitch} arrow applied to a vector $(1, 2, 3, 4, 5)$ should evaluate to $(1, 2, 3, 5, 4)$. We propose a more accurate
name for the \hs{second} statement, namely \hs{last}.

\par 
While \hs{aSwitch} is of type $Vec_n^{Int}$, the expression \hs{last aSwitch} must be of type $Vec_{k+n}^{Int}, k \ge
0$. Typically this is hard to express in a functional language, but in a dependently typed language this should be possible to
express in the data type.

\par
There are multiple languages with dependent types out there. On with a pretty good connection to Haskell is Agda. It is written in
Haskell and can also compile into it. Nonetheless the developers of Agda say, compiling is not one of the main features of their
language. In fact type checking is of much more interest in a dependent language. The following describes how an arrow type class
would look in a functional language with dependent types.


\begin{haskell}
record VArrow (_~~>_ : Set -> Set → Set) : Set₁ where 
  field
    arr    : forall {B n m}     -> (Vec B n -> Vec B m) -> (Vec B n) ~~> (Vec B m)
    firsts : forall {B n m k}   -> Vec B n ~~> Vec B m -> Vec B (n + k) ~~> Vec B (m + k)    
    lasts  : forall {B n m k}   -> Vec B n ~~> Vec B m -> Vec B (n + k) ~~> Vec B (m + k) 
    _>>>_  : forall {B n m k}   -> Vec B n ~~> Vec B m -> Vec B m ~~> Vec B k -> Vec B n ~~> Vec B k
    _***_  : forall {B n m k j} -> Vec B n ~~> Vec B m -> Vec B k ~~> Vec B j -> Vec B (n + k) ~~> Vec B (m + j)
    _&&&_  : forall {B n m k}   -> Vec B n ~~> Vec B m -> Vec B n ~~> Vec B k -> Vec B n ~~> Vec B (m + k) 
  infixr 2 _>>>_
  infixr 2 _***_
  infixr 2 _&&&_
\end{haskell}

\begin{itemize}
\item 
  \begin{itemize}
  \item tuple arrows => kartesische produkt kategorien
  \item vector arrows => produkt familien kategorien 
  \end{itemize}

\item problems with agda / dependent typed solutions 
  \begin{itemize}
  \item ebenfalls last lässt sich nicht sauber definieren / Gründe??? 
  \end{itemize}
\end{itemize}

\subsection{Vector-Arrows are not Arrows}
-  :+: and :-:
- \ldots

Conclusion: That is dependent typing and Haskell is not (yet) a dependently typed function programming language. And all in all it
seems that the Vec-Type together with the Arrows-Instances is too much dependent typing for Haskell


\section{Copeing with \hs{arr}-Problem}

\subsection{ForSyDe: Using the AST of the arr argument}
In order to transform a usual Haskell function into an hardware block, ForSyDe stores the AST of that function which is used later
to synthesis VHDL.  \

\subsection{Show-Type-Class (or Typeable)}


\subsection{Generalized Arrows -- avoiding arr}




\bibliographystyle{plain}
\bibliography{Bibliography}
\end{document}
