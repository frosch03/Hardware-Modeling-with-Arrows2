
\documentclass{article}
\title{Hardware Modeling with Functional Datastructures: Functions, Arrows, Tupels, Vectors, and Inspection} 

\begin{document}

\section{Introduction}
With the rise of rapid prototyping and development methodologies in the hardware community, hardware has started to get softer. FPGA's are a
major contributor for this trend. It is only natural to take benefits out of the existing software engineering concepts. This can be seen in
hardware description languages like VHDL or Verilog. Both have taken their syntax from common languages like C and ADA. Those two are
typical imperative languages, but there are arguments that declarative languages fit more natural to the problem of hardware modeling.
Functional programming languages like \emph{Haskell} are declarative.

\begin{itemize}
  \item \emph{Referential transference}: While imperative languages force the programmer to prescribe the control flow a declarative
    language is stateless. Stateless means, that the programmer does not describe the control flow, but the compiler is able to decide the
    order of execution. Therefore concurrency isn't something that needs to be simulated (like it's done in System-C) but fits natural in
    the language and the developed code.
  \item \emph{Composition}: Functional programs are build out of the composition of small pieces. Again this attributes to hardware design
    where complex systems are also build out of the composition of smaller pieces.
  \item \emph{Type systems}: Functional languages like Haskell come with an expressive type system which helps to detect errors early and
    also helps the developer to a cleaner design.
  \item \emph{Higher-order functions}: Typical functional design techniques like higher order functions can be used to abstract common
    circuit structures, so that the developers task is to instantiate them in order to get circuits.
  \item \emph{Lazy evaluation}: With the help of lazy evaluating languages it is easy to express infinite data structures, which also maps
    natural to stream processing hardware specifications. 
\end{itemize}

This properties lead to some interesting development possibilities which are not new in the functional programming world, but are rather
unusual if not impossible in languages like VHDL. With the use of higher order functions developers are able to transform circuits just to
their needed behavior. The clean detachment of the languages semantics from the circuits specification is the key that leads to an extreme
flexible design. Last but not least the clear expressiveness of functional languages makes it easy to \emph{1:} reason, \emph{2:} realize
and \emph{3:} analyze functional programs. % TODO do i need to cite sheeran here?

\par
In fact, these are old news, functional programming pioneers pointed to the use of functional languages as perfect hardware design languages
long before. \cite{Sheeran} %O'Donnell and all the others\ldots

From the authors point of view it is not only natural to describe hardware with the help of functional programming languages, but also it is
the logical step.

\section{Hardware Modeling in Haskell: Recent Approaches}

\section{Why Arrows?}

... and not Monads or functions or simple datatypes ...

\begin{itemize}
\item Interface (i.\,e. \hs{***}, \hs{&&&}, \hs{>>>}) is natural for combining hardware blocks
\item Functional Functions are too powerfull; arrows allow to downgrade functions' features.
\item Arrows compromise deep and shallow embedding, and seem to pick the benfits of both.a
\item Arrows resemble premonoidal effect categories and ...   are a common way for category theorists to model the
semantics of programming languages in a maximal generic way. In this view, arrows are executable maximum generic
semantic specifications. With this genericity, one can hope to be able to do many things with such a specification:
Execution, Synthesis, Proofing, (dependend on the concrete instance of the arrow)
\end{itemize}

\section{First Approach: Classical Arrows}

\subsection{Implementation}

Generating Netlists, ...

\subsection{Simple Example}

\subsection{CRC}

\subsection{Problems with this approach}

\begin{itemize}
\item Problems with nested tupels. Re-Tupeling is not very handy.
\item Tupels are not an appropriate model for hardware wires. (e.g. input for a 3-ary AND: is it (x,(y,z)) or ((x,y),z)) 
\item Type for \hs{arr}-Argument (e.g. \hs{\x y z -> (...)}) is not available for later calculations (to generate the netlists, usw.)
\end{itemize}

The tupel-problem could be avoided (at least superficially) with the use of Patterson's proc-Notation. The proc-Notation
abstracts the tupels ...


\section{Coping with the Tupel-Problem -- "`Vector-Arrows"'}

\begin{haskell}
class VArrow a where
  arr    :: (Vec n b -> Vec m b) -> a (Vec n b) (Vec m b)
  (>>V)  :: a (Vec n b) -> 
  firsts :: 
  (&&&)  :: 
  (***)  :: 
\end{haskell}

\subsection{Horn-Clause-Solution}

\subsection{Type-Family-Solutions}

-  :+: and :-:
- ....

Conclusion: That is dependent typing and Haskell is not (yet) a dependently typed function programming laguage. And all
in all it seems that the Vec-Type together with the Arrows-Instances is too much dependent typing for Haskell

\subsection{Using a dependently types language}

\section{Coping with \hs{arr}-Problem}

\subsection{ForSyDe: Using the AST of the arr argument}

In order to transform a usual Haskell function into an hardware block, ForSyDe stores the AST of that function which is
used later to synthesis VHDL.

\subsection{Show-Type-Class (or Typeable)}

\subsection{Generalized Arrows -- avoiding arr}


\end{document}
